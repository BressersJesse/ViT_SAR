import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from timm.models.vision_transformer import VisionTransformer
from tqdm import tqdm
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast
import rasterio
import numpy as np
from pathlib import Path
from pyproj import Transformer
import os

# Class mapping (must match training)
GLC_CLASS_MAPPING = {
    11: 0, 12: 1, 20: 2, 51: 3, 52: 4,
    61: 5, 62: 6, 71: 7, 72: 8, 81: 9,
    82: 10, 91: 11, 92: 12, 121: 13, 122: 14,
    130: 15, 140: 16, 150: 17, 181: 18, 182: 19,
    183: 20, 184: 21, 185: 22, 186: 23, 187: 24,
    191: 25, 192: 26, 200: 27, 210: 28, 220: 29
}
REVERSE_MAPPING = {v: k for k, v in GLC_CLASS_MAPPING.items()}

# 2. Modified Vision Transformer Model
class SARViT(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.vit = VisionTransformer(
            img_size=224,
            patch_size=16,
            in_chans=2,  # Two input channels (VH and VV)
            num_classes=30,  # Remove classification head
            embed_dim=768,
            depth=12,
            num_heads=12,
        )
        
        # Segmentation head
        self.decoder = nn.Sequential(
            nn.Conv2d(768, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Upsample(scale_factor=2, mode='bilinear'),
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Upsample(scale_factor=2, mode='bilinear'),
            nn.Conv2d(128, num_classes, kernel_size=1)
        )

    def forward(self, x):
        # Get patch embeddings
        x = self.vit.patch_embed(x)
        cls_token = self.vit.cls_token.expand(x.shape[0], -1, -1)
        x = torch.cat((cls_token, x), dim=1)
        x = x + self.vit.pos_embed
        x = self.vit.blocks(x)
        x = self.vit.norm(x)
        
        # Remove cls token and reshape
        x = x[:, 1:].permute(0, 2, 1).view(x.size(0), 768, 14, 14)
        
        # Decode to segmentation mask
        x = self.decoder(x)
        x = torch.nn.functional.interpolate(x, size=(224, 224), mode='bilinear')
        return x

def sanitize_path(path):
    """Remove /reynolds prefix if present"""
    return path[len('/reynolds'):] if path.startswith('/reynolds') else path

def predict_and_save():
    # Load model
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SARViT(num_classes=30).to(device)
    model.load_state_dict(torch.load("best_sar_vit.pth", map_location=device))
    model.eval()

    # Get input paths
    vh_path = sanitize_path(input("Enter VH image path: ").strip('"'))
    vv_path = sanitize_path(input("Enter VV image path: ").strip('"'))
    output_dir = sanitize_path(input("Enter output directory: ").strip('"'))
    
    # Create output filename
    output_filename = "prediction.tif"
    output_path = os.path.join(output_dir, output_filename)
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Load SAR data with georeferencing info
    with rasterio.open(vh_path) as src:
        vh = src.read(1).astype(np.float32)
        meta = src.meta.copy()
        transform = src.transform
        crs = src.crs

    with rasterio.open(vv_path) as src:
        vv = src.read(1).astype(np.float32)

    # Normalization (same as training)
    vh = (vh - np.mean(vh)) / np.std(vh)
    vv = (vv - np.mean(vv)) / np.std(vv)

    # Create input tensor
    image = np.stack([vh, vv], axis=0)
    image = torch.from_numpy(image).unsqueeze(0).float().to(device)

    # Predict
    with torch.no_grad():
        output = model(image)
    pred_mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()

    # Convert back to original class IDs
    pred_original = np.vectorize(REVERSE_MAPPING.get)(pred_mask, -9999).astype(np.int16)

    # Create new GeoTIFF from scratch
    meta.update({
        'driver': 'GTiff',
        'height': pred_original.shape[0],
        'width': pred_original.shape[1],
        'count': 1,
        'dtype': 'int16',
        'nodata': -9999,
        'crs': crs,
        'transform': transform,
        'compress': 'lzw'
    })

    with rasterio.open(output_path, 'w', **meta) as dst:
        dst.write(pred_original[np.newaxis, :, :])  # Add channel dimension

    print(f"Prediction saved to {output_path}")

if __name__ == "__main__":
    predict_and_save()
