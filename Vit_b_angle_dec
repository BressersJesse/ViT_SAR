import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from timm.models.vision_transformer import VisionTransformer
from tqdm import tqdm
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast
import rasterio
import numpy as np
from pathlib import Path
from pyproj import Transformer
import os

# Class mapping (must match training)
GLC_CLASS_MAPPING = {
    11: 0, 51: 1, 121: 2, 130: 3, 140: 4,
    181: 5, 191: 6, 150: 7, 210: 8, 220: 9
}
REVERSE_MAPPING = {v: k for k, v in GLC_CLASS_MAPPING.items()}

# 2. Modified Vision Transformer Model
class SARViT(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.vit = VisionTransformer(
            img_size=224,
            patch_size=16,
            in_chans=2,  # Two input channels (VH and VV)
            num_classes=10,  # Remove classification head
            embed_dim=768,
            depth=12,
            num_heads=12,
        )
        
        # Segmentation head
        self.decoder = nn.Sequential(
            nn.Conv2d(768, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Upsample(scale_factor=2, mode='bilinear'),
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Upsample(scale_factor=2, mode='bilinear'),
            nn.Conv2d(128, num_classes, kernel_size=1)
        )

    def forward(self, x):
        # Get patch embeddings
        x = self.vit.patch_embed(x)
        cls_token = self.vit.cls_token.expand(x.shape[0], -1, -1)
        x = torch.cat((cls_token, x), dim=1)
        x = x + self.vit.pos_embed
        x = self.vit.blocks(x)
        x = self.vit.norm(x)
        
        # Remove cls token and reshape
        x = x[:, 1:].permute(0, 2, 1).view(x.size(0), 768, 14, 14)
        
        # Decode to segmentation mask
        x = self.decoder(x)
        x = torch.nn.functional.interpolate(x, size=(224, 224), mode='bilinear')
        return x

def sanitize_path(path):
    """Remove /reynolds prefix if present"""
    return path[len('/reynolds'):] if path.startswith('/reynolds') else path

def predict_on_directories():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SARViT(num_classes=10).to(device)
    model.load_state_dict(torch.load("best_sar_vit_b_angle.pth", map_location=device))
    model.eval()

    # Get input paths
    vh_dir = sanitize_path(input("Enter VH directory path: ").strip('"'))
    vv_dir = sanitize_path(input("Enter VV directory path: ").strip('"'))
    angle_dir = sanitize_path(input("Enter angle directory path: ").strip('"'))
    output_dir = sanitize_path(input("Enter output directory path: ").strip('"'))
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # File handling with alignment check
    vh_files = sorted(os.listdir(vh_dir))
    vv_files = sorted(os.listdir(vv_dir))
    angle_files = sorted(os.listdir(angle_dir))

    # Verify file alignment
    assert len(vh_files) == len(vv_files) == len(angle_files), \
        "Mismatched number of VH/VV/Angle files"
    
    # Matching training parameters
    REF_ANGLE_RAD = np.deg2rad(35)  # Must match training reference angle
    EPS = 1e-3  # Must match training epsilon

    for vh_file, vv_file, angle_file in tqdm(zip(vh_files, vv_files, angle_files), 
                                           total=len(vh_files)):
        # Verify filename consistency
        base_name = os.path.splitext(vh_file)[0]

        # Load data
        vh_path = Path(vh_dir) / vh_file
        vv_path = Path(vv_dir) / vv_file
        angle_path = Path(angle_dir) / angle_file

        with rasterio.open(vh_path) as src:
            vh = src.read(1).astype(np.float32)
            meta = src.meta.copy()
            transform = src.transform
            crs = src.crs

        with rasterio.open(vv_path) as src:
            vv = src.read(1).astype(np.float32)

        with rasterio.open(angle_path) as src:
            theta_inc = np.deg2rad(src.read(1).astype(np.float32))

        # Apply identical processing to training
        def process_band(band, theta_inc):
            # Angle correction
            corrected = band * (np.cos(REF_ANGLE_RAD)**2) / (np.cos(theta_inc)**2 + EPS)
            # Standardization using corrected stats
            return (corrected - np.mean(corrected)) / np.std(corrected + EPS)

        vh_processed = process_band(vh, theta_inc)
        vv_processed = process_band(vv, theta_inc)

        # Create input tensor
        image = np.stack([vh_processed, vv_processed], axis=0)
        image = torch.from_numpy(image).unsqueeze(0).float().to(device)

        # Prediction
        with torch.no_grad():
            output = model(image)
        pred_mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()

        # Map to original classes
        pred_original = np.vectorize(REVERSE_MAPPING.get)(pred_mask, -9999).astype(np.int16)

        # Save output
        output_path = Path(output_dir) / f"{base_name}_pred.tif"
        with rasterio.open(output_path, 'w', **meta) as dst:
            dst.write(pred_original[np.newaxis, :, :])

    print(f"Predictions saved to {output_dir}")


if __name__ == "__main__":
    predict_on_directories()
